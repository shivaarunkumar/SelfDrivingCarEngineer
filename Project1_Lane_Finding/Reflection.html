<!DOCTYPE html>
<html>
<head>
<title>writeup_template.md</title>
<meta http-equiv="Content-type" content="text/html;charset=UTF-8">

<style>
/* https://github.com/microsoft/vscode/blob/master/extensions/markdown-language-features/media/markdown.css */
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

body {
	font-family: var(--vscode-markdown-font-family, -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif);
	font-size: var(--vscode-markdown-font-size, 14px);
	padding: 0 26px;
	line-height: var(--vscode-markdown-line-height, 22px);
	word-wrap: break-word;
}

#code-csp-warning {
	position: fixed;
	top: 0;
	right: 0;
	color: white;
	margin: 16px;
	text-align: center;
	font-size: 12px;
	font-family: sans-serif;
	background-color:#444444;
	cursor: pointer;
	padding: 6px;
	box-shadow: 1px 1px 1px rgba(0,0,0,.25);
}

#code-csp-warning:hover {
	text-decoration: none;
	background-color:#007acc;
	box-shadow: 2px 2px 2px rgba(0,0,0,.25);
}

body.scrollBeyondLastLine {
	margin-bottom: calc(100vh - 22px);
}

body.showEditorSelection .code-line {
	position: relative;
}

body.showEditorSelection .code-active-line:before,
body.showEditorSelection .code-line:hover:before {
	content: "";
	display: block;
	position: absolute;
	top: 0;
	left: -12px;
	height: 100%;
}

body.showEditorSelection li.code-active-line:before,
body.showEditorSelection li.code-line:hover:before {
	left: -30px;
}

.vscode-light.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(0, 0, 0, 0.15);
}

.vscode-light.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(0, 0, 0, 0.40);
}

.vscode-light.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-dark.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 255, 255, 0.4);
}

.vscode-dark.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 255, 255, 0.60);
}

.vscode-dark.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-high-contrast.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 160, 0, 0.7);
}

.vscode-high-contrast.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 160, 0, 1);
}

.vscode-high-contrast.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

img {
	max-width: 100%;
	max-height: 100%;
}

a {
	text-decoration: none;
}

a:hover {
	text-decoration: underline;
}

a:focus,
input:focus,
select:focus,
textarea:focus {
	outline: 1px solid -webkit-focus-ring-color;
	outline-offset: -1px;
}

hr {
	border: 0;
	height: 2px;
	border-bottom: 2px solid;
}

h1 {
	padding-bottom: 0.3em;
	line-height: 1.2;
	border-bottom-width: 1px;
	border-bottom-style: solid;
}

h1, h2, h3 {
	font-weight: normal;
}

table {
	border-collapse: collapse;
}

table > thead > tr > th {
	text-align: left;
	border-bottom: 1px solid;
}

table > thead > tr > th,
table > thead > tr > td,
table > tbody > tr > th,
table > tbody > tr > td {
	padding: 5px 10px;
}

table > tbody > tr + tr > td {
	border-top: 1px solid;
}

blockquote {
	margin: 0 7px 0 5px;
	padding: 0 16px 0 10px;
	border-left-width: 5px;
	border-left-style: solid;
}

code {
	font-family: Menlo, Monaco, Consolas, "Droid Sans Mono", "Courier New", monospace, "Droid Sans Fallback";
	font-size: 1em;
	line-height: 1.357em;
}

body.wordWrap pre {
	white-space: pre-wrap;
}

pre:not(.hljs),
pre.hljs code > div {
	padding: 16px;
	border-radius: 3px;
	overflow: auto;
}

pre code {
	color: var(--vscode-editor-foreground);
	tab-size: 4;
}

/** Theming */

.vscode-light pre {
	background-color: rgba(220, 220, 220, 0.4);
}

.vscode-dark pre {
	background-color: rgba(10, 10, 10, 0.4);
}

.vscode-high-contrast pre {
	background-color: rgb(0, 0, 0);
}

.vscode-high-contrast h1 {
	border-color: rgb(0, 0, 0);
}

.vscode-light table > thead > tr > th {
	border-color: rgba(0, 0, 0, 0.69);
}

.vscode-dark table > thead > tr > th {
	border-color: rgba(255, 255, 255, 0.69);
}

.vscode-light h1,
.vscode-light hr,
.vscode-light table > tbody > tr + tr > td {
	border-color: rgba(0, 0, 0, 0.18);
}

.vscode-dark h1,
.vscode-dark hr,
.vscode-dark table > tbody > tr + tr > td {
	border-color: rgba(255, 255, 255, 0.18);
}

</style>

<style>
/* Tomorrow Theme */
/* http://jmblog.github.com/color-themes-for-google-code-highlightjs */
/* Original theme - https://github.com/chriskempson/tomorrow-theme */

/* Tomorrow Comment */
.hljs-comment,
.hljs-quote {
	color: #8e908c;
}

/* Tomorrow Red */
.hljs-variable,
.hljs-template-variable,
.hljs-tag,
.hljs-name,
.hljs-selector-id,
.hljs-selector-class,
.hljs-regexp,
.hljs-deletion {
	color: #c82829;
}

/* Tomorrow Orange */
.hljs-number,
.hljs-built_in,
.hljs-builtin-name,
.hljs-literal,
.hljs-type,
.hljs-params,
.hljs-meta,
.hljs-link {
	color: #f5871f;
}

/* Tomorrow Yellow */
.hljs-attribute {
	color: #eab700;
}

/* Tomorrow Green */
.hljs-string,
.hljs-symbol,
.hljs-bullet,
.hljs-addition {
	color: #718c00;
}

/* Tomorrow Blue */
.hljs-title,
.hljs-section {
	color: #4271ae;
}

/* Tomorrow Purple */
.hljs-keyword,
.hljs-selector-tag {
	color: #8959a8;
}

.hljs {
	display: block;
	overflow-x: auto;
	color: #4d4d4c;
	padding: 0.5em;
}

.hljs-emphasis {
	font-style: italic;
}

.hljs-strong {
	font-weight: bold;
}
</style>

<style>
/*
 * Markdown PDF CSS
 */

 body {
	font-family: -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif, "Meiryo";
	padding: 0 12px;
}

pre {
	background-color: #f8f8f8;
	border: 1px solid #cccccc;
	border-radius: 3px;
	overflow-x: auto;
	white-space: pre-wrap;
	overflow-wrap: break-word;
}

pre:not(.hljs) {
	padding: 23px;
	line-height: 19px;
}

blockquote {
	background: rgba(127, 127, 127, 0.1);
	border-color: rgba(0, 122, 204, 0.5);
}

.emoji {
	height: 1.4em;
}

code {
	font-size: 14px;
	line-height: 19px;
}

/* for inline code */
:not(pre):not(.hljs) > code {
	color: #C9AE75; /* Change the old color so it seems less like an error */
	font-size: inherit;
}

/* Page Break : use <div class="page"/> to insert page break
-------------------------------------------------------- */
.page {
	page-break-after: always;
}

</style>

<script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
</head>
<body>
  <script>
    mermaid.initialize({
      startOnLoad: true,
      theme: document.body.classList.contains('vscode-dark') || document.body.classList.contains('vscode-high-contrast')
          ? 'dark'
          : 'default'
    });
  </script>
<p><strong>Finding Lane Lines on the Road</strong></p>
<p>The goals / steps of this project are the following:</p>
<ul>
<li>Make a pipeline that finds lane lines on the road</li>
<li>Reflect on your work in a written report</li>
</ul>
<hr>
<h3 id="reflection">Reflection</h3>
<h3 id="1-describe-your-pipeline-as-part-of-the-description-explain-how-you-modified-the-drawlines-function">1. Describe your pipeline. As part of the description, explain how you modified the draw_lines() function.</h3>
<p>My pipeline consisted of 6 steps (including the final overlay).</p>
<ol>
<li>
<p><strong>Conversion to grayscale</strong>
In this step the image was converted from the imported RGB format to Grayscale</p>
</li>
<li>
<p><strong>Gaussian Blurring</strong>
Applied a low pass gaussian filter to eliminate high frequency noise. Used a kernel size of 5 as the feature set of interest to us is pretty large in dimensions. The low pass filtering will have minimal effect on feature extraction.</p>
</li>
<li>
<p><strong>Canny Edge Detection</strong>
Applied Canny edge detection with <em>low_threshold</em> of <strong>100</strong> and a <em>high_threshold</em> of <strong>225</strong>
These values seemed to work best for the challenge exercise. I wider window seemed better for the first two exercises.</p>
</li>
<li>
<p><strong>Polygon Masking</strong>
I initially employed a heuristic threshold for the first two exercises.</p>
<pre class="hljs"><code><div>vertices = np.array([[(<span class="hljs-number">100</span>,<span class="hljs-number">539</span>),(<span class="hljs-number">450</span>, <span class="hljs-number">325</span>), (<span class="hljs-number">520</span>, <span class="hljs-number">325</span>), (<span class="hljs-number">880</span>,<span class="hljs-number">539</span>)]], dtype=np.int32)
</div></code></pre>
<p>However, this will only work for images of this specific dimension. This proved to be a problem when attempting to solve the optional challenge. Hence, I adopted a more adaptive polygon selection that was dependent on the image shape.</p>
<pre class="hljs"><code><div>vertices = np.array([[(<span class="hljs-number">.1</span>*width,<span class="hljs-number">.95</span>*height),(<span class="hljs-number">.45</span>*width, <span class="hljs-number">.6</span>*height), (<span class="hljs-number">.55</span>*width, <span class="hljs-number">.6</span>*height), (<span class="hljs-number">.9</span>*width,<span class="hljs-number">.95</span>*height)]], dtype=np.int32)
</div></code></pre>
</li>
<li>
<p><strong>Line Detection - Using Hough Transforms</strong>
Use the following parameter set to detect lines from the edge detected image.</p>
<pre class="hljs"><code><div>rho = <span class="hljs-number">1</span>
theta = np.pi/<span class="hljs-number">180</span> <span class="hljs-comment"># radians</span>
threshold = <span class="hljs-number">10</span>
min_line_len = <span class="hljs-number">50</span>
max_line_gap =<span class="hljs-number">50</span>
</div></code></pre>
<p>Detection of lines wasn't a big issue but extrapolation of the line required some work. As suggested I used the computed slopes to categorize the detected lines (left and right lane markers). However, there was some miscategorization due to smaller line segments on both sides of the aisle with slopes in the incorrect direction.</p>
<p><em>So I decided to divide the image into two halves assuming the camera is mounted in the center of the vehicle and the image in itself is centerd.</em></p>
<p>I looked for lines with a negative slope in the first vertical half of the image to detect the left lane and a similar approach on the second half for the right lane.</p>
<p>This worked pretty well for the first two exercises but caused issues for the optional challenge. There were almost horizontal lines detected in the image that impacted the line fitting that follows. So I decided to only look at slopes &gt; ~26deg</p>
<p>After this I used linear fit on the extracted points to extrapolate the line between:</p>
<pre class="hljs"><code><div>ylim = [int(<span class="hljs-number">.6</span>*height),int(<span class="hljs-number">.95</span>*height)]
</div></code></pre>
<p><img src="./processing.jpg" alt="Intermediate Processing Results"></p>
</li>
<li>
<p><strong>Overlay</strong>
This was just a simple overlay on the original RGB image.
<img src="./Processed0.jpg" alt="Processed Result"></p>
</li>
</ol>
<h3 id="2-identify-potential-shortcomings-with-your-current-pipeline">2. Identify potential shortcomings with your current pipeline</h3>
<p>There are several potential shortcomings in this pipeline:</p>
<ul>
<li>The current detection alogrithms do not work very well when the image is over exposed. This is observable in the optional challenge where the left lane isn't detected briefly.</li>
<li>If the camera or the image was a bit off centered this algorithm crumble owing to the relative segmentation of the image.</li>
<li>The filtering and detection is pretty simplistic, a noisy image in low light will cause a lot of issues.</li>
</ul>
<h3 id="3-suggest-possible-improvements-to-your-pipeline">3. Suggest possible improvements to your pipeline</h3>
<ul>
<li>Better Filtering</li>
<li>Run on low light images</li>
<li>Improve the hough transform parameters</li>
</ul>

</body>
</html>
