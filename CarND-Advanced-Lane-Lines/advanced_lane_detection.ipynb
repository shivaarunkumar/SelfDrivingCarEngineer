{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.image as mplimg\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "%matplotlib qt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera Calibration\n",
    "We will compute the calibration matrix and distortion coefficients given a set of chess board images\n",
    "[tutorial] (https://docs.opencv.org/2.4/doc/tutorials/calib3d/camera_calibration/camera_calibration.html)\n",
    "Camera Matrix (C) --> Converts 3D real world points P(x,y,z) to 2D image points p(x,y) [pinhole camera model]\n",
    "P ~ Cp\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['.vscode', 'advanced_lane_detection.ipynb', 'calibration_params.p', 'camera_cal', 'challengevidframes', 'challenge_video.mp4', 'examples', 'example_writeup.pdf', 'harderchallengevidframes', 'harder_challenge_video.mp4', 'ldpackage', 'LICENSE', 'output_images', 'pipeline.py', 'processed_challenge_video.mp4', 'processed_harder_challenge_video.mp4', 'processed_project_video.mp4', 'projectvidframes', 'project_video.mp4', 'pTransformData.p', 'README.md', 'run.py', 'set_git.sh', 'test_images', 'writeup_template.md', '__pycache__']\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x1fc4c573f88>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "os.chdir('D:\\\\Courses\\\\Udacity\\\\Workbooks\\\\ND013\\\\SelfDrivingCarEngineer\\\\CarND-Advanced-Lane-Lines')\n",
    "print(os.listdir())\n",
    "calimg1 = mplimg.imread(\".\\camera_cal\\calibration1.jpg\")\n",
    "\n",
    "plt.imshow(calimg1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The number of object points for this project is 9x6\n",
    "# prepare object points\n",
    "objp = np.zeros((6*9,3),np.float32)\n",
    "objp[:,:2] = np.mgrid[0:9, 0:6].T.reshape(-1,2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d points in real world space\n",
    "imgpoints = [] # 2d points in image plane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "20\n"
    }
   ],
   "source": [
    "# Curate Image List\n",
    "images = glob.glob('.\\camera_cal\\calibration*.jpg')\n",
    "\n",
    "print(len(images))\n",
    "# Step through all of the calibration images\n",
    "for idx,fname in enumerate(images):\n",
    "    image = cv2.imread(fname) #BGR\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    #Identify Chessboard Corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (9,6), None)\n",
    "\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "        \n",
    "        # Draw and display the corners\n",
    "        cv2.drawChessboardCorners(image, (9,6), corners, ret)\n",
    "        cv2.imshow('Image', image)\n",
    "        \n",
    "        cv2.waitKey(500)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(720, 1280)\n"
    }
   ],
   "source": [
    "img = cv2.imread(images[0])\n",
    "img_size = img.shape\n",
    "print(img_size[0:2])\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size[0:2],None,None)\n",
    "#Save the camera calibration results for later use\n",
    "calibration = {}\n",
    "calibration[\"CameraMatrix\"] = mtx\n",
    "calibration[\"DistortionCoeff\"] = dist\n",
    "calibration[\"RotationalVectors\"] = rvecs\n",
    "calibration[\"TranslationalVectors\"] = tvecs\n",
    "pickle.dump(calibration,open(\"calibration_params.p\",\"wb\"))\n",
    "\n",
    "# Undistort calibration images\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    dst = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "    ax1.imshow(img)\n",
    "    ax1.set_title('Original Image', fontsize=30)\n",
    "    ax2.imshow(dst)\n",
    "    ax2.set_title('Undistorted Image', fontsize=30)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computer Vision Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def undistort(image):\n",
    "    calibration_file = open(\"calibration_params.p\",'rb')\n",
    "    params = pickle.load(calibration_file)\n",
    "    CMtx = params[\"CameraMatrix\"]\n",
    "    distC = params[\"DistortionCoeff\"]\n",
    "    undistorted_image = cv2.undistort(image, CMtx, distC, None, CMtx)\n",
    "    return undistorted_image\n",
    "\n",
    "def gaussian_blur(img, kernel_size=3):\n",
    "    blurred_image = cv2.GaussianBlur(img,(kernel_size, kernel_size),0)\n",
    "    return blurred_image\n",
    "\n",
    "def canny_thresh(img, thresh_low=0, thresh_high=255):\n",
    "    edges = cv2.Canny(img, thresh_low, thresh_high)\n",
    "    return edges\n",
    "\n",
    "def abs_sobel_thresh(img, orient='x', sobel_kernel=3, thresh=(0, 255)):\n",
    "    # Calculate directional gradient\n",
    "    # Apply threshold\n",
    "    thresh_min = thresh[0]\n",
    "    thresh_max = thresh[1]\n",
    "    \n",
    "    dx=(orient=='x')\n",
    "    dy=(orient=='y')\n",
    "    sobel = cv2.Sobel(img,cv2.CV_64F,dx,dy,sobel_kernel)\n",
    "    abs_sobel = np.absolute(sobel)\n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "    \n",
    "    binary_output = np.zeros_like(scaled_sobel)\n",
    "    binary_output[(scaled_sobel >= thresh_min) & (scaled_sobel<=thresh_max)] = 1\n",
    "    \n",
    "    return binary_output\n",
    "\n",
    "def gradient_thresh(image,sobel_kernel=3,x_thresh=(0,255),y_thresh=(0,255)):\n",
    "    gradx = abs_sobel_thresh(image, 'x', sobel_kernel, thresh=x_thresh)\n",
    "    grady = abs_sobel_thresh(image, 'y', sobel_kernel, thresh=y_thresh)\n",
    "    binary_output = np.zeros_like(image)\n",
    "    binary_output[(gradx==1) & (grady==1)]=1\n",
    "    return binary_output\n",
    "\n",
    "\n",
    "\n",
    "def polar_thresh(image,sobel_kernel,mag_thresh=(0,255),ang_thresh=(0,np.pi/2)):\n",
    "    sobelx = cv2.Sobel(image,cv2.CV_64F,1,0,None,sobel_kernel)\n",
    "    sobely = cv2.Sobel(image,cv2.CV_64F,0,1,None,sobel_kernel)\n",
    "    mag, ang = cv2.cartToPolar(sobelx, sobely)\n",
    "    scaled_mag = np.uint8(255*mag/np.max(mag))\n",
    "    binary_output = np.zeros_like(image)\n",
    "    binary_output[(scaled_mag >= mag_thresh[0]) & (scaled_mag<=mag_thresh[1]) & (ang >= ang_thresh[0]) & (ang<=ang_thresh[1])] = 1\n",
    "    binary_output_debug_mag = np.zeros_like(image)\n",
    "    binary_output_debug_mag[(scaled_mag >= mag_thresh[0]) & (scaled_mag<=mag_thresh[1])]=1\n",
    "    binary_output_debug_ang = np.zeros_like(image)\n",
    "    binary_output_debug_ang[(ang >= ang_thresh[0]) & (ang<=ang_thresh[1])]=1\n",
    "\n",
    "    # plt.figure()\n",
    "    # plt.imshow(scaled_mag, cmap='gray')\n",
    "    # plt.figure()\n",
    "    # plt.imshow(binary_output_debug_mag, cmap='gray')\n",
    "    # plt.figure()\n",
    "    # plt.imshow(binary_output_debug_ang, cmap='gray')\n",
    "\n",
    "    return binary_output\n",
    "def color_thresh(image,ch=1,thresh=(0,255)):\n",
    "    #Assume a BGR image is being passed in\n",
    "    channel = image[:,:,ch] # First Channel    \n",
    "    binary_output = np.zeros_like(channel)\n",
    "    binary_output[(channel>thresh[0]) & (channel<=thresh[1])]=1\n",
    "    return binary_output\n",
    "\n",
    "def S_thresh(image, thresh=(0,255)):\n",
    "    hls = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "    s = hls[:,:,2]\n",
    "    binary_output = np.zeros_like(s)\n",
    "    binary_output[(s>=thresh[0]) & (s<=thresh[1])]=1\n",
    "    return binary_output\n",
    "\n",
    "\n",
    "def warp(image):\n",
    "    transform_file = open(\"pTransformData.p\",'rb')\n",
    "    params = pickle.load(transform_file)\n",
    "    M = params[\"M\"]\n",
    "    warped = cv2.warpPerspective(image,M,image.shape[1::-1])   \n",
    "    return warped\n",
    "\n",
    "def unwarp(image):\n",
    "    transform_file = open(\"pTransformData.p\",'rb')\n",
    "    params = pickle.load(transform_file)\n",
    "    Minv = params[\"Minv\"]\n",
    "    unwarped = cv2.warpPerspective(image,Minv,image.shape[1::-1])    \n",
    "    return unwarped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perspective Transform Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()\n",
    "plt.close('all')\n",
    "test_images = glob.glob('.\\\\test_images\\\\*.jpg')   \n",
    "\n",
    "subset=[test_images[0]]\n",
    "for fname in test_images:\n",
    "    img = cv2.imread(fname)\n",
    "    \n",
    "    undistorted_image = undistort(img)\n",
    "    \n",
    "    gray = cv2.cvtColor(undistorted_image,cv2.COLOR_BGR2GRAY)\n",
    "    filtered = gaussian_blur(gray,kernel_size=5)\n",
    "    edges = canny_thresh(filtered,thresh_low=100,thresh_high=240)\n",
    "    # gradthresh = gradient_thresh(filtered,sobel_kernel=3,x_thresh = (20,100), y_thresh =(20,100))\n",
    "    gradthresh = abs_sobel_thresh(filtered,orient='x', sobel_kernel=5,thresh=(50,200))\n",
    "    polarthresh = polar_thresh(filtered, sobel_kernel=3, mag_thresh=(100, 255), ang_thresh=(np.pi/4,60*np.pi/180))\n",
    "    colorthresh = color_thresh(undistorted_image,ch=2,thresh=(200,255))\n",
    "    sthresh = S_thresh(undistorted_image, thresh=(200, 255))\n",
    "    bin_output = np.zeros_like(gray)\n",
    "    bin_output[(gradthresh==1) | (sthresh == 1)] = 1\n",
    "    \n",
    "    f, ((ax1, ax2),(ax3,ax4),(ax5,ax6),(ax7,ax8)) = plt.subplots(4, 2, figsize=(20,20))\n",
    "    ax1.imshow(img)\n",
    "    ax1.set_title('Original Image', fontsize=30)\n",
    "    ax2.imshow(undistorted_image)\n",
    "    ax2.set_title('Undistorted Image', fontsize=30)\n",
    "    ax3.imshow(filtered, cmap = 'gray')\n",
    "    ax3.set_title('Filtered Image', fontsize=30)\n",
    "    ax4.imshow(edges, cmap='gray')\n",
    "    ax4.set_title('Canny Edge Detected Image', fontsize=30)\n",
    "    ax5.imshow(gradthresh, cmap = 'gray')\n",
    "    ax5.set_title('Gradient Thresholded Image', fontsize=30)\n",
    "    ax6.imshow(polarthresh, cmap='gray')\n",
    "    ax6.set_title('Polar Thresholded Image', fontsize=30)\n",
    "    plt.tight_layout()\n",
    "    ax7.imshow(colorthresh, cmap = 'gray')\n",
    "    ax7.set_title('Color Thresholded Image', fontsize=30)\n",
    "    ax8.imshow(sthresh, cmap='gray')\n",
    "    ax8.set_title('Saturation Thresholded Image', fontsize=30)\n",
    "    plt.tight_layout()\n",
    "    # plt.savefig(os.path.join('output_images', os.path.basename(fname))+'_visualize_thresh.png')\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.imshow(bin_output,cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warp Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(720, 1280)\n(1280, 720)\n"
    },
    {
     "output_type": "error",
     "ename": "error",
     "evalue": "OpenCV(4.2.0) C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\drawing.cpp:2435: error: (-215:Assertion failed) p.checkVector(2, CV_32S) >= 0 in function 'cv::polylines'\n",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-069fe87fb8ba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0msrc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m475\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m526\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m810\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m526\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1062\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m680\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m240\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m680\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# top left, top right, bottom left, bottom right\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpolylines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mundistorted_image\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msuptitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'undistored image'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.2.0) C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\drawing.cpp:2435: error: (-215:Assertion failed) p.checkVector(2, CV_32S) >= 0 in function 'cv::polylines'\n"
     ]
    }
   ],
   "source": [
    "image = cv2.imread('.\\\\test_images\\straight_lines1.jpg')\n",
    "\n",
    "undistorted_image = undistort(image)\n",
    "print(undistorted_image.shape[0:2])\n",
    "print(undistorted_image.shape[1::-1])\n",
    "# plt.figure()\n",
    "# plt.imshow(undistorted_image)\n",
    "src = np.float32([[475,526],[810,526],[1062,680],[240,680]]) # top left, top right, bottom left, bottom right\n",
    "plt.figure()\n",
    "plt.imshow(cv2.polylines(undistorted_image,np.int32(src),True,(0,0,255),3))\n",
    "plt.suptitle('undistored image')\n",
    "\n",
    "dst = np.float32([[300,500],[900,500],[900,719],[300,719]]) # Heuristic offset of 100 from each corner\n",
    "M = cv2.getPerspectiveTransform(src,dst,cv2.INTER_LINEAR)\n",
    "print(M)\n",
    "warped = cv2.warpPerspective(undistorted_image,M,undistorted_image.shape[1::-1])\n",
    "plt.figure()\n",
    "plt.imshow(cv2.polylines(warped,np.int32(dst),True,(0,0,255),3))\n",
    "plt.suptitle('undistored image')\n",
    "\n",
    "Minv = cv2.getPerspectiveTransform(dst,src,cv2.INTER_LINEAR)\n",
    "unwarped = cv2.warpPerspective(warped,Minv,warped.shape[1::-1])\n",
    "plt.figure()\n",
    "plt.imshow(cv2.polylines(unwarped,np.int32(src),True,(0,0,255),3))\n",
    "plt.suptitle('undistored image')\n",
    "\n",
    "pTransform = {}\n",
    "pTransform['M']=M\n",
    "pTransform['Minv']=Minv\n",
    "pickle.dump(pTransform,open('pTransformData.p','wb'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "test_images = glob.glob('.\\\\test_images\\\\*.jpg')   \n",
    "\n",
    "subset=[test_images[0]]\n",
    "for fname in test_images:\n",
    "    image = cv2.imread(fname)\n",
    "    undistorted_image = undistort(image)\n",
    "    warped = warp(undistorted_image)\n",
    "    unwarped = unwarp(warped)\n",
    "    \n",
    "    f, ((ax1,ax2),(ax3,ax4)) = plt.subplots(2,2, figsize=(20,20))\n",
    "    f.suptitle(os.path.basename(fname),fontsize=30)\n",
    "    ax1.imshow(image)\n",
    "    ax1.set_title('Original Image', fontsize=30)\n",
    "    ax2.imshow(undistorted_image)\n",
    "    ax2.set_title('Undistorted Image', fontsize=30)\n",
    "    ax3.imshow(warped)\n",
    "    ax3.set_title('Warped Image', fontsize=30)\n",
    "    ax4.imshow(unwarped)\n",
    "    ax4.set_title('Unwarped Image', fontsize=30)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join('output_images', os.path.basename(fname))+'_birds_eye.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "LinAlgError",
     "evalue": "SVD did not converge in Linear Least Squares",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-20e88989d5dc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    131\u001b[0m     \u001b[0mbinary_warped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwarp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbin_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m     \u001b[0mout_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_polynomial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbinary_warped\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_img\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-20e88989d5dc>\u001b[0m in \u001b[0;36mfit_polynomial\u001b[1;34m(binary_warped)\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[0mleftx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlefty\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrightx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrighty\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_lane_pixels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbinary_warped\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m     \u001b[0mleft_fit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpolyfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlefty\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleftx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m     \u001b[0mright_fit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpolyfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrighty\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrightx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[1;31m# Generate x and y values for plotting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mpolyfit\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\numpy\\lib\\polynomial.py\u001b[0m in \u001b[0;36mpolyfit\u001b[1;34m(x, y, deg, rcond, full, w, cov)\u001b[0m\n\u001b[0;32m    627\u001b[0m     \u001b[0mscale\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlhs\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mlhs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    628\u001b[0m     \u001b[0mlhs\u001b[0m \u001b[1;33m/=\u001b[0m \u001b[0mscale\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 629\u001b[1;33m     \u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlstsq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlhs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrhs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrcond\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    630\u001b[0m     \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mscale\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m  \u001b[1;31m# broadcast scale coefficients\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mlstsq\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\numpy\\linalg\\linalg.py\u001b[0m in \u001b[0;36mlstsq\u001b[1;34m(a, b, rcond)\u001b[0m\n\u001b[0;32m   2304\u001b[0m         \u001b[1;31m# lapack can't handle n_rhs = 0 - so allocate the array one larger in that axis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2305\u001b[0m         \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_rhs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2306\u001b[1;33m     \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgufunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrcond\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2307\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mm\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2308\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\numpy\\linalg\\linalg.py\u001b[0m in \u001b[0;36m_raise_linalgerror_lstsq\u001b[1;34m(err, flag)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_raise_linalgerror_lstsq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"SVD did not converge in Linear Least Squares\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_linalg_error_extobj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLinAlgError\u001b[0m: SVD did not converge in Linear Least Squares"
     ]
    }
   ],
   "source": [
    "def find_lane_pixels(binary_warped):\n",
    "    # Take a histogram of the bottom half of the image\n",
    "    histogram = np.sum(binary_warped[binary_warped.shape[0]//2:,:], axis=0)\n",
    "    # Create an output image to draw on and visualize the result\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]//2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "    # HYPERPARAMETERS\n",
    "    # Choose the number of sliding windows\n",
    "    nwindows = 9\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 100\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 50\n",
    "\n",
    "    # Set height of windows - based on nwindows above and image shape\n",
    "    window_height = np.int(binary_warped.shape[0]//nwindows)\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Current positions to be updated later for each window in nwindows\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = binary_warped.shape[0] - (window+1)*window_height\n",
    "        win_y_high = binary_warped.shape[0] - window*window_height\n",
    "        ### TO-DO: Find the four below boundaries of the window ###\n",
    "        win_xleft_low = leftx_current - margin # Update this\n",
    "        win_xleft_high = leftx_current + margin   # Update this\n",
    "        win_xright_low = rightx_current - margin  # Update this\n",
    "        win_xright_high = rightx_current + margin  # Update this\n",
    "        \n",
    "        # Draw the windows on the visualization image\n",
    "        \n",
    "        cv2.rectangle(out_img,(win_xleft_low,win_y_low),\n",
    "        (win_xleft_high,win_y_high),(0,255,0), 2) \n",
    "        cv2.rectangle(out_img,(win_xright_low,win_y_low),\n",
    "        (win_xright_high,win_y_high),(0,255,0), 2) \n",
    "        \n",
    "        ### TO-DO: Identify the nonzero pixels in x and y within the window ###\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xleft_low) &  (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xright_low) &  (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        \n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        \n",
    "        \n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        \n",
    "        ### TO-DO: If you found > minpix pixels, recenter next window ###\n",
    "        ### (`right` or `leftx_current`) on their mean position ###\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "        \n",
    "        \n",
    "\n",
    "    # Concatenate the arrays of indices (previously was a list of lists of pixels)\n",
    "    try:\n",
    "        left_lane_inds = np.concatenate(left_lane_inds)\n",
    "        right_lane_inds = np.concatenate(right_lane_inds)\n",
    "    except ValueError:\n",
    "        # Avoids an error if the above is not implemented fully\n",
    "        pass\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    return leftx, lefty, rightx, righty, out_img\n",
    "\n",
    "\n",
    "def fit_polynomial(binary_warped):\n",
    "    # Find our lane pixels first\n",
    "    leftx, lefty, rightx, righty, out_img = find_lane_pixels(binary_warped)\n",
    "    \n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "\n",
    "\n",
    "    ## Visualization ##\n",
    "    # Colors in the left and right lane regions\n",
    "    out_img[lefty, leftx] = [255, 0, 0]\n",
    "    out_img[righty, rightx] = [0, 0, 255]\n",
    "\n",
    "    # Plots the left and right polynomials on the lane lines\n",
    "    plt.plot(left_fitx, ploty, color='yellow')\n",
    "    plt.plot(right_fitx, ploty, color='yellow')\n",
    "\n",
    "    return out_img\n",
    "\n",
    "\n",
    "plt.close('all')\n",
    "test_images = glob.glob('.\\\\test_images\\\\*.jpg')   \n",
    "\n",
    "subset=[test_images[0]]\n",
    "for fname in test_images:\n",
    "    image = cv2.imread(fname)\n",
    "    undistorted_image = undistort(image)\n",
    "    gray = cv2.cvtColor(undistorted_image,cv2.COLOR_BGR2GRAY)\n",
    "    filtered = gaussian_blur(gray,kernel_size=5)\n",
    "    polarthresh = polar_thresh(filtered, sobel_kernel=3, mag_thresh=(100, 255), ang_thresh=(np.pi/4,60*np.pi/180))\n",
    "    colorthresh = color_thresh(undistorted_image,ch=2,thresh=(200,255))\n",
    "    sthresh = S_thresh(undistorted_image, thresh=(200, 255))\n",
    "    bin_output = np.zeros_like(gray)\n",
    "    bin_output[(colorthresh==1) & ((polarthresh==1) | (sthresh == 1))] = 1\n",
    "    binary_warped = warp(bin_output)\n",
    "\n",
    "    out_img = fit_polynomial(binary_warped)\n",
    "\n",
    "    plt.imshow(out_img)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bit02025930ee1f4ad68b65406c498cb016",
   "display_name": "Python 3.7.7 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}